#!/usr/bin/env python
#!-*-coding:utf-8 -*-
#!@time    :2018/10/3 17:20
#!@Author :SINGLE
#!@File   :BaseApp.py
from urllib.robotparser import RobotFileParser
import re,json,requests,time
from requests.exceptions import RequestException

def is_can_catch():
    rp=RobotFileParser('http://www.maoyan.com/robots.txt')
    rp.read()
    print(rp.can_fetch('*','https://maoyan.com/board/4?offset=0'))
def parse_page(pageIndex):
    try:
        response = requests.get('https://maoyan.com/board/4', data='{"offset":' + str(pageIndex) + '}')
        if response.status_code==200:
            pattern=re.compile('<p.*?>.*?:(.*?)</p><p.*?>.*?:(.*?)</p>',re.S)
            items=re.findall(pattern,response.text)
            return items
            for item in items:
                return {'actor':item[0],'time':item[1]}
    except RequestException:
        return None

if  __name__=='__main__':
    # if  not is_can_catch():
    #     return
    page = parse_page(0)
    print(page)
